# Sampling Accuracy

The following CRAN packages must be installed:

| Required CRAN Packages |
|-------------------|
|tidyverse          |
|remotes            |

The following GitHub packages must be installed:

| Required GitHub Packages |
|--------------------------|
|dstanley4/learnSampling |


A GitHub package can be installed using the code below:

```{r, eval = FALSE}
remotes::install_github("dstanley4/learnsampling")
```


## Overview

Researchers are usually interested in describing the attributes of a population; numbers that describe the population are called parameters. Two parameters that are frequently of interest are the mean and variance of the population. Unfortunately, it’s rarely possible to obtain information from every member of a population to calculate a parameter. Consequently, researchers use subsets of the population called samples to estimate parameters. Numbers calculated from sample data are called statistics. Typically, sample statistics are used to estimate population parameters.

Sample statistics, however, often differ from population parameters. The difference between a sample statistic and the population parameter occurs because the sample data is random subset of the population data — with correspondingly fewer observations. This difference is typically refered to as **sampling error**.

Sometimes a sample statistic will be higher than the population parameter; other times the sample statistic will be lower than the population parameter. Because random sampling is used to select the sample data the direction and magnitude of the difference between the sample statistic and the population parameter will vary randomly. 

Sample accuracy refers to the extent to which sample statistics correctly estimate the population parameter. We typically used the terms biased and unbiased to describe the accuracy of sample statistics. Consider a scenario where we take many thousands of samples from the same population. For each sample, we calculate a statistic (e.g., the mean). If the average of the sample statistics (e.g., sample means) equals the population parameter (e.g., population mean) then we refer to the statistic as being unbiased. In contrast, if the average of the sample statistics (e.g., sample means) does not equal the population parameter (e.g., population mean) then we refer to the statistic as being biased. 

Further complicating matters is  the fact that the formula used for a sample statistic may, or may not, be the same as the formula used for the corresponding population parameter. This occurs because the purpose of the sample statistic is typically not to describe the sample. Rather the purpose of the sample statistic is to estimate the population parameter. Depending on the parameter, you may or may not be able to use the same formula with sample data as you would with population data.

Also keep in mind that, even if you conduct experiments, the distinction between samples and populations is relevant to you. Consider a scenario where you run an experiment to test the effectiveness of a particular drug. Half the rats are assigned to a placebo condition (e.g., saline injection) whereas the other half of the rats are assigned to the drug condition (e.g., drug injection). Recognize that the placebo-condition rats are considered a sample from a much larger population of all rats who could have received the placebo. Likewise, the drug-condition rats are considered a sample of a much large population of all rats who could have received the drug. Indeed, when you conduct your analyses on this experiment the results do not tell you about the rats in your study - rather they tell you about rats in general (i.e., the larger populations of rats). Therefore, when we discuss the importance of estimating a population parameter from a sample realize that it applies to both experimental and survey research.


## Data for the chapter

In this chapter we will use a population of heights to learn about random sampling. To engage in the learning activities you need to activate the required packages: 

```{r, include=FALSE}
library(tidyverse)
library(learnSampling)
```

```{r}
library(tidyverse)
library(learnSampling)
```

Next, we create a large population with 100,000 people using the get_height_population() command:

```{r}
pop_data <- get_height_population() 
```

The print() command can be used to confirm that the population contains 100,000 people. We see that each row in pop_data represents a single person. There is a column called height that contains the heights for everyone in the population.

```{r}
print(pop_data)
```

## Notation

In the formulas below, when we refer to the population, we use uppercase letters to indicate members ($X$) or the size ($N$). The population mean is indicated by the symbol $\mu$. In contrast, when we refer to the sample, we use lowercase letters to indicate members ($x$) or the size ($n$). The sample mean is indicated by the symbol $\bar{x}$. A single bar above a letter indicates a mean. If we calculate the average of several sample means we indicate this with the symbol $\bar{\bar{x}}$. A double bar above a letter indicates a mean of means. Make sure you notice the similarities between subsequent population and sample formulas even though the notation often differs.

## Estimating $\mu$

We are interested in the sample mean ($\bar{x}$) to the extent that it provides an accurate estimate of the population mean ($\mu$). The population mean is calculated using Formula \@ref(eq:popmeanch5). In this formula, the letter $N$ corresponds to the number of people in the population.

\begin{equation} 
\mu = \frac{\sum{X}}{N}
      (\#eq:popmeanch5)
\end{equation} 


We can calculate the population mean for the height column of pop_data using the summarise() and mean() commands. The mean() command uses Formula \@ref(eq:popmeanch5). We see in the output that the population mean is 172.48 ($\mu = 172.48$).

```{r}
pop_data %>%
  summarise(pop_mean = mean(height)) %>%
  as.data.frame()
```


As noted previously, we rarely have access to data from an entire population. Consequently, we use the sample mean as an estimate of the population mean. The sample mean, $\bar{x}$, is a statistic calculated using the using Formula \@ref(eq:samplemeanch5) below. The bar above the $x$, indicates that it is a mean. Notice that Formula \@ref(eq:popmeanch5) and Formula \@ref(eq:samplemeanch5) are the same - even though they use different notation. In this formula, the letter $n$ corresponds to the number of people in the sample.


\begin{equation} 
\bar{x} = \frac{\sum{x}}{n}
      (\#eq:samplemeanch5)
\end{equation} 

Because a sample mean (a statistic) is calculated using a random subset of the population it is likely to differ from the population mean (a parameter). If you, inaccurately, believe that you can learn something meaningful from a single study, this fact may be disconcerting. Statisticians know, however, that rarely can you learn anything from a single study, or even a small set of studies. Consequently, they are more interested in the extent to which sample means are right, on average. That is, they are interested in the extent to which the mean of many sample means ($\bar{\bar{x}}$) corresponds to the population mean ($\mu$). The mean of many sample means can be calculated using Formula \@ref(eq:samplemeanmeanch5) below. In this formula, the letter $k$ corresponds to the number of sample means.


\begin{equation} 
\bar{\bar{x}} = \frac{\sum{\bar{x}}}{k}
      (\#eq:samplemeanmeanch5)
\end{equation} 


If the mean of the sample means, $\bar{\bar{x}}$, equals the population mean, $\mu$, then the sample mean is an unbiased (or accurate) estimate of the population mean. Figure \@ref(fig:showbias) illustrates the concept of accuracy/bias with a distribution of sample means (i.e., $\bar{x}$). Accuracy/bias is an index of the extent to which the mean of many sample means, $\bar{\bar{x}}$, deviates from the population mean, $\mu$. 

```{r showbias, echo=FALSE, out.width = "80%", fig.cap = "Sampling accuracy and precision"}
knitr::include_graphics("ch_samples/images/sampling_accuracy.png")
```

We can assess bias, as illustrated in the above figure by drawing a large number of samples from a population with the code below. Our goal is calculate a mean for each sample so that we have a sampling distribution of means. In theory, we should take an infinite number of samples, however, to be practical we will take 50000 samples to create an approximate sampling distribution of means. We use the code below to do so:

```{r, eval = FALSE}
many_samples <- get_M_samples(pop.data = pop_data, 
                              pop.column.name = height,
                              n = 10,
                              number.of.samples = 50000)
```
```{r, eval = FALSE, echo = FALSE}
saveRDS(many_samples, file = "ch_samples/many_samples_n10.RDS")
```
```{r, eval=TRUE}
many_samples <- readRDS("ch_samples/many_samples_n10.RDS")
```

We use the print() command to see the first few rows of the 50000 samples:

```{r}
print(many_samples)
```

Each row of many_samples represents a sample of 10 people. Each column of many_samples indicates a sample statistic. You can see that for each sample/row we indicate "n" (the sample size) and "sample_mean" (the mean of the population), and a few other statistics. Even though all the samples came from the same population you can see how the values in the sample_mean column vary across samples/rows. 


```{r, eval = FALSE, echo=FALSE}
pg <- ggplot(data = pop_data,
       mapping = aes(x = height)) +
  geom_density() +
  coord_cartesian(xlim = c(140, 205)) +
  labs(x = "Heights of Individuals", y = "Probability") +
  scale_x_continuous(breaks = seq(120, 220, by = 5)) +
  theme_classic()


sdg <- ggplot(data = many_samples,
       mapping = aes(x = sample_mean)) +
  geom_density(adjust = 1.3) +
  coord_cartesian(xlim = c(140, 205)) +
  labs(x = "Mean Height for each sample", y = "Probability") +
  scale_x_continuous(breaks = seq(120, 220, by = 5)) +
  theme_classic()

png(filename = "ch_samples/images/bothdist.png", width = 12*300, height = 6*300, res = 300)
gridExtra::grid.arrange(pg,sdg, nrow=2)
dev.off()
```
 
 
```{r bothdist, echo = FALSE, out.width = "80%", fig.scap = "Sampling distribution of the mean.", fig.cap = "Sampling distribution of the mean. The population of individuals is presented at the top and filled with X's to remind you they are individuals. There are more individuals than X's. The sampling distribution of means is presented in the bottom part of the graph. The sampling distribution of means is filled with $\\bar{x}$'s to remind you that it is sample means being graphed. There are more means than $\\bar{x}$'s. The population mean (green line) and the mean of sample means (blue line) are in the same spot, indicating high accuracy (i.e., no bias)."}
knitr::include_graphics("ch_samples/images/sampling_dist.png")
```
 
 
Above, in Figure \@ref(fig:bothdist), we present a graph comparing the distribution of peoples heights (i.e., the population) to the distribution of sample means based on those heights (i.e., the sampling distribution). The sample means plotted are the 50000 sample means, from the sample_mean column. Recall the population mean for heights is $\mu = 172.48$ cm. Notice that most of the sample means cluster around this value. Also notice that there is considerable variability about this value. Any given sample mean ($\bar{x}$) may differ substantially from the population mean ($\mu = 172.48$). This variability illustrates the challenges with learning something from a single study - particularly a study with a small sample size. Many of the sample means fall quite far from the population mean.

### Assessing bias  

Statisticians, recognizing the limitations of a single study, are not particularly concerned if a single sample mean deviates from the population mean. That said, statisticians are very concerned as to whether or not the results of a large number of studies are correct -- on average. That is, does the average of many sample means correspond to the population mean? If, on average, the sample mean does corresponds to the population mean, it is accurate and we refer to it as an unbiased estimator. Visually, this appears to be the case. But in the code below we confirm it numerically.

```{r}
many_samples %>%
  summarise(mean_of_sample_mean = mean(sample_mean)) %>%
  as.data.frame()
```

We find that the average of the 50000 sample means is 172.47 which is very close to the population mean of 172.48. Note that when we did this, we used the same formula to calculate the sample mean (Formula \@ref(eq:samplemeanch5)) as we did the population mean (Formula \@ref(eq:popmeanch5)), although the notations differed. The average of the sample means was not identical to the population mean but it was very close - it would have been exactly the same with many more samples (i.e., an infinite number of samples). Therefore, we conclude the sample mean provides an unbiased estimate of the population mean. In other words, it makes sense to use the sample mean as an estimate of the population mean. If we try to estimate the population mean with a sample mean we will, on average, be correct; although any given sample/study mean might be "wrong".


## Estimating $\sigma^2$

We are interested in the sample variance ($s^2$) to the extent that it provides an estimate of the population variance ($\sigma^2$). We begin by reviewing population variance. The population variance is calculated using Formula \@ref(eq:popvarch5):

\begin{equation} 
\sigma^2 = \frac{\sum{(X - \mu)^2}}{N}
      (\#eq:popvarch5)
\end{equation} 

We can calculate the population variance for the height column of pop_data using the summarise() and var.pop() commands. The var.pop() command uses Formula \@ref(eq:popvarch5). We see in the output that the population variance is 157.5 ($\sigma^2 = 157.5$).

```{r}
pop_data %>%
  summarise(pop_var = var.pop(height)) %>%
  as.data.frame()
```

### Assessing bias  


The formula for sample variance with an $n$ in the denominator is, unfortunately, a biased estimator of population variance (formula below).

$$
\begin{aligned} 
s^2 = \frac{\sum{(x - \bar{x})^2}}{n}
\end{aligned} 
$$


Estimates of the population variance are systematically too low when you use a sample variance formula with an $n$ in the denominator. We can see that this is true by examining the many_samples data. In these data, the column sample_var_n contains the variance for the sample calculated with the above formula. Below we use code to obtain the average of the sample_var_n column over the 50000 samples. If this average equals the population variance of 157.5 then variance, using $n$ in the denominator, is an unbiased estimator of the population variance.

```{r}
many_samples %>%
  summarise(mean_of_var_n = mean(sample_var_n)) %>%
  as.data.frame()
```

You can see the average of sample_var_n column (141.54) is much smaller than the population variance (157.5). That is, the average of the sample variances, using $n$ in the denominator, was smaller than the population variance. Consequently, sample variance (using $n$ in the denominator) provides a biased estimate of the population variance. If we try to estimate the population variance with sample variance (using $n$ in the denominator) we will, on average, be wrong.

Fortunately, there is a sample-level formula that estimates the population variance without bias (see Hayes). An unbiased estimate of the population variance can be obtained if we calculate the sample variance but divide by $n - 1$ instead of $n$. The unbiased estimate is calculated using Formula \@ref(eq:samplevarn1ch5).

\begin{equation} 
s^2 = \frac{\sum{(x - \bar{x})^2}}{n-1}
      (\#eq:samplevarn1ch5)
\end{equation} 

In the many_samples data, the column sample_var_n_1 was generated using Formula \@ref(eq:samplevarn1ch5). We can evaluate the quality of Formula \@ref(eq:samplevarn1ch5), using $n-1$, by averaging the values in the sample_var_n_1 column.

```{r}
many_samples %>%
  summarise(mean_of_var_n_1 = mean(sample_var_n_1)) %>%
  as.data.frame()
```

We see that the average of the 50000 values using $n-1$ in the denominator is 157.27 which is very close to the population variance of 157.46. These numbers would have been identical with an infinite number of samples. Consequently, when we use $n-1$ in the denominator we have an unbiased estimate of the population variance. If we try to estimate the population variance with a sample variance, using $n-1$ in the denominator, we will, on average, be right.

You may wonder at this point, when we use $n-1$ in the denominator of the sample variance, can we still think of it as the average of the squared differences from the mean? The short answer is yes. When you use $n-1$ in the denominator of the sample variance you are not calculating the variance for the group people in the sample. Rather, you are estimating the variance for the much larger group of people in the population. Consequently, it makes sense to think of sample variance, using $n-1$, as an estimate of the average of the squared differences/errors *in the population*. That is, it makes sense to think of sample variance, using $n-1$, as an estimate of the average of the squared differences between each person in the population and the population mean.

## Estimating $\sigma$


The population standard deviation is calculated using  Formula \@ref(eq:popsdch5) below.

\begin{equation} 
\sigma = \sqrt{\frac{\sum{(X- \mu)^2}}{N}}
      (\#eq:popsdch5)
\end{equation} 

Due to the above findings for variance, we estimate the population standard deviation using Formula \@ref(eq:samplesd1ch5) below.

\begin{equation} 
s = \sqrt{\frac{\sum{(x - \bar{x})^2}}{n-1}}
      (\#eq:samplesd1ch5)
\end{equation} 



## Estimating $\rho$

The population-level correlation, $\rho$, is estimated by the sample-level correlation, $r$. The value for $r$ can be calculated using Formula \@ref(eq:sampler5) below.

\begin{equation} 
r =  \frac{\Sigma (x - \bar{x})(y - \bar{y})}{\sqrt{\Sigma (x - \bar{x})^2\Sigma (y - \bar{y})^2}}
      (\#eq:sampler5)
\end{equation} 


Sample-level correlations, $r$, often differ from the population-level correlation ($\rho$) due to sampling error. We can confirm that sample correlations are not substantially biased with a simulation. That is, we can confirm that the average of many sample correlations ($r$) roughly equals the population correlation ($\rho$) using a simulation. We say "roughly equal" because $r$ is technically a biased estimator of $\rho$ but the bias is sufficiently small that it can be ignored [@schmidt2014methods].

We have the height and weight for 300000 people that comprise our population (fictious data). This data can be loaded with the command below.

```{r}
library(tidyverse)
pop_data <- read_csv(file = "data_cor_pop.csv")
```

The print() command reveals there are 300000 rows and two columns (weight and height). Each row represents a different person in the population.

```{r}
print(pop_data)
```

We can obtain the population correlation, $\rho$, by correlating the weight and height columns:

```{r}
cor(pop_data)
```

We see from this matrix that the population correlation  (*N* = 300000) between weight and height is $\rho$ = .50 (with rounding), see Figure \@ref(fig:rdistplot)A.

To examine the extent to which this population correlation, $\rho$ = .50, is estimated by the sample statistic, $r$, we need to take a large number of samples. Therefore, we take 50000 samples (each *n* = 75) and calculate the correlation for each:

```{r, eval = FALSE}
set.seed(1)
many_samples <- get_r_samples_from_population_data(data = pop_data,
                                                   n = 75,
                                                   number.of.samples = 50000)
```


```{r, eval = TRUE, echo = FALSE}
many_samples <- readRDS("ch_samples/many_samples_r_n75_rho50.RDS")
```

We can examine the first few rows of many_samples using the print() command. There are 50000 rows and each row represent a different sample of 75 people. The correlation between height and weight for each sample is presented in the $r$ column. 

```{r}
print(many_samples)
```

If you examine the first row carefully you see a sample correlation of $r = .38$ based on $n$ = 75. This sample correlation is illustrated in Figure \@ref(fig:rdistplot)B and it is just one of the 50000 sample correlations. The distribution of the 50000 sample correlations is illustrated in in Figure \@ref(fig:rdistplot)C.

Even though the population correlation is $\rho = .50$ there is considerable variability in the sample correlations, $r$. Each sample correlation is based on a subset of the population data (i.e., 75 of the 300000 rows). Consequently, the sample correlations differ from the population correlation due to sampling error. The differences among the sample correlations can be quite large. Indeed, as the code below reveals, some sample correlation were as low as $r = .06$ and as high as $r = .77$ -- even though the population correlation was $\rho = .50$.


```{r}
many_samples %>%
  summarise(min_r = min(r),
            max_r = max(r))
```

### Assessing bias  

Even though the sample correlations usually differed from the population correlation we are not concerned. We recognize that there is little to be learned from a single study. We are more concerned as to whether the average of a large number of sample correlations is correct. We assess this with the code below.

```{r}
many_samples %>%
  summarise(mean_r = mean(r))
```

You can see that the mean of the sample-level correlations is $\bar{r} = .497$ which is very close to the population-level correlation $\rho = .50$ (.4999951 without rounding). Consequently, for practical purposes, we don't worry about the sample correlation being a biased estimator of the population correlation. On average, sample correlation are correct - even though any single sample correlation is likely incorrect due to sampling error (i.e., the fact it is based on a small subset of the population). 

```{r, include=FALSE, eval = FALSE}
library(learnSampling)
library(tidyverse)
N <- 300000
n <- 75
mu <- c(150, 170)
sd <- c(8, 12)
k = 50000

cormatrix <- diag(2)
cormatrix[1,2] <- .5
cormatrix[2,1] <- .5
rhopop <- expression(rho == ".50")

set.seed(1)
pop_rho <- mvrnorm_cor(n = N, mu = mu, sd = sd, cormatrix = cormatrix, empirical = TRUE)
pop_rho <- pop_rho %>% round(1)
pop_data <- as.data.frame(pop_rho)
names(pop_data) <- c("weight", "height")

#write_csv(pop_data, path = "data_cor_pop.csv")

# set.seed(1)
# many_samples <- get_r_samples_from_population_data(data = pop_data,
#                                                    n = n,
#                                                    number.of.samples = k)
# 
# saveRDS(many_samples, file = "ch_samples/many_samples_r_n75_rho50.RDS")

many_samples <- readRDS("ch_samples/many_samples_r_n75_rho50.RDS")

set.seed(1)
single_sample = sample_n(pop_data, size = n)


pop_graph <- ggplot(data = pop_data,
                  mapping = aes(x = height, y = weight)) +
  geom_point(alpha = .30) +
  scale_x_continuous(breaks = seq(100, 250, by = 20)) +
  scale_y_continuous(breaks = seq(70, 250, by = 20)) +
  coord_cartesian(xlim = c(110,250), ylim = c(70, 210)) +
  labs(title = expression("Population correlation")) +
  annotate(geom = "text", x= 220, y = 125, label = rhopop, parse = TRUE) +
  theme_classic()

sample_graph <- ggplot(data = single_sample,
                  mapping = aes(x = height, y = weight)) +
  geom_point() +
  scale_x_continuous(breaks = seq(100, 250, by = 20)) +
  scale_y_continuous(breaks = seq(70, 250, by = 20)) +
  coord_cartesian(xlim = c(110,250), ylim = c(70, 210)) +
  labs(title = "A single sample correlation (n = 75)") +
  annotate(geom = "text", x= 220, y = 135, label = "r = .38") +
  theme_classic()



r_graph <- ggplot(data = many_samples,
                  mapping = aes(x = r)) +
  geom_density(adjust = 1.8) +
  scale_x_continuous(breaks = seq(0, 1, by = .1)) +
  coord_cartesian(xlim = c(0,1)) +
  annotate(geom = "text", x= .65, y = 3, label = "Each    ", hjust = 0) +
  annotate(geom = "text", x= .65, y = 2.6, label = "based", hjust = 0) +
  annotate(geom = "text", x= .65, y = 2.2, label = "on n = 75", hjust = 0) +
  labs(title = sprintf("Distribution of %g sample correlations", k),
       x = "Sample correlation",
       y = "Density") +
  theme_classic()

png(filename = "ch_samples/images/rdist_example.png",
    width = 4*300,
    height = 10*300,
    res = 300)
gridExtra::grid.arrange(pop_graph, sample_graph, r_graph)
dev.off()

```


```{r rdistplot, fig.cap="Correlation sampling distribution", echo = FALSE, out.height="70%", out.width="70%"}
knitr::include_graphics("ch_samples/images/r_sampling_dist_edit.png")
```
  

## Overview

In this chapter we have illustrated how population parameters can be estimated by sample statistics; these are summarized below:

\doublespacing

|  | Parameter  | Estimated by this statistic | 
| ---   | ---         |  ---   |
| Mean |$\mu = \frac{\sum{X}}{N}$ | $\bar{x} = \frac{\sum{x}}{n}$|
| Variance |$\sigma^2 = \frac{\sum{(X - \mu)^2}}{N}$  | $s^2 = \frac{\sum{(x - \bar{x})^2}}{n-1}$ |
|          |     |  $s_{pooled}^2  = \frac{(n_1 -1)s_1^2 + (n_2 -1)s_2^2}{n_1 + n_2-2}$|
| Standard deviation |$\sigma = \sqrt{\frac{\sum{(X - \mu)^2}}{N}}$  | $s =\sqrt{\frac{\sum{(x - \bar{x})^2}}{n-1}}$ |
|          |     |  $s_{pooled}  = \sqrt{\frac{(n_1 -1)s_1^2 + (n_2 -1)s_2^2}{n_1 + n_2-2}}$|
| Correlation | $\rho =  \frac{\Sigma (X - \mu_X)(Y - \mu_Y)}{\sqrt{\Sigma (X - \mu_X)^2\Sigma (Y - \mu_Y)^2}}$ | $r =  \frac{\Sigma (x - \bar{x})(y - \bar{y})}{\sqrt{\Sigma (x - \bar{x})^2\Sigma (y - \bar{y})^2}}$ |

\singlespacing

## Meta-analysis

It may seem odd that we used so many simulations to investigate the properties of statistics. Surely, researchers don't do that "in the real world". In fact, researchers who are aware of the enormous impact of sampling error know that single studies have little informational value. They recognize that any single study has a high probability of being misleading. Consequently, these individuals survey the literature and find all the studies on a single topic (possibly thousands of studies). An average of the results of all of the thousands of studies can then be calculated and reported. This process is referred to as conducting a meta-analysis; and it perfectly corresponds to the process we used in the simulations. A meta-analysis finds "the truth" of what is happening at the population level by averaging all of the studies on that topic.

## A joke

Now that you understand the logic for assessing bias, we present an old statistics joke.

> "A physicist, a chemist, and a statistician go hunting. The physicist shoots at a deer and misses by 2 meters to the left. The chemist shoots and misses by 2 meters to the right. The statistician immediately yells "We got it!"


## Key Points

1. Samples are of interest because they help us estimate attributes of a population.

2. Sample *statistics* estimate population *parameters*.

3. Due to the fact that sample statistics are based on a random subset of the population (i.e., a sample) they often differ substantially from the population parameter. This illustrates that informational value of a single study is typically quite low.

4. A statistic is unbiased if the average of the sample statistics, over many thousand of samples, equals the population parameter.

5. To avoid bias, sometimes the formula for a sample statistics differs from the formula for the population parameter.

6. Meta-analyses are used in the "real world" the way we used simulations in this chapter.




